{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### install dependencies:\n",
    "\n",
    "# might need to install opencv\n",
    "!pip3 install Cython cupy-cuda112 cupy-cuda102   # Probably only need one of these but it works so I'm gonna leave it for now.\n",
    "!pip3 install pyyaml==5.1\n",
    "\n",
    "# Torch 1.8.1 does not work despite being the latest stable release. As such, use 1.7. \n",
    "# Cuda version on MAGEOHub is currently 11.3 - cu110 all works fine.\n",
    "\n",
    "# To be tried once the bug with torch 1.8 has been fixed \n",
    "#!pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and check versions and cuda availability, and resources\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic imports:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# tensorboard?\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output\n",
    "\n",
    "# necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The following two cells just determine that the setup is working correctly on a standard example.\n",
    "\n",
    "# Get image, hash wget line if already downloaded.\n",
    "# Just unhash if running this code for the first time, i.e. input.jpg has not yet been downloaded\n",
    "\n",
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")\n",
    "\n",
    "# Create config\n",
    "cfg = get_cfg()\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "\n",
    "#cfg.merge_file = 'https://github.com/facebookresearch/detectron2/blob/master/configs/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml'\n",
    "#cfg.merge_from_file(\"./detectron2/configs/COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "\n",
    "# Bit worried this line won't work for everyone - if it doesn't, go to https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md to find a link to the model weights\n",
    "\n",
    "#cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl\"\n",
    "\n",
    "# Here we just get the pre-trained weights straight from facebook hosting website\n",
    "\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl'\n",
    "\n",
    "\n",
    "\n",
    "# Create predictor\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Make prediction\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36839845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "image = cv2.cvtColor(v.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)\n",
    "display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18891665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the inevitable error messages are useful.\n",
    "CUDA_LAUNCH_BLOCKING=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65675ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Within this script, this is the LATEST, and BRILLIANT loop\n",
    "\n",
    "def get_tree_dicts(directory):\n",
    "    classes = ['tree']\n",
    "    dataset_dicts = []\n",
    "    for filename in [file for file in os.listdir(directory) if file.endswith('.geojson')]:\n",
    "        json_file = os.path.join(directory, filename)\n",
    "        with open(json_file) as f:\n",
    "            img_anns = json.load(f)\n",
    "        \n",
    "        \n",
    "        \n",
    "        record = {}\n",
    "        \n",
    "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
    "        # Make sure we have the correct height and width\n",
    "        height, width = cv2.imread(filename).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = filename\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        record[\"image_id\"] = filename[0:400]\n",
    "        print(filename[0:400])\n",
    "            \n",
    "        \n",
    "\n",
    "        objs = []\n",
    "        for features in img_anns['features']:\n",
    "            anno = features['geometry']\n",
    "            # print(\"##### HERE IS AN ANNO #####\", anno)...weirdly sometimes (but not always) have to make 1000 into a np.array\n",
    "            px = [a[0] for a in anno['coordinates'][0]]\n",
    "            py = [np.array(height) - a[1] for a in anno['coordinates'][0]]\n",
    "            # print(\"### HERE IS PY ###\", py)\n",
    "            poly = [(x, y) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "            # print(\"#### HERE ARE SOME POLYS #####\", poly)\n",
    "            obj = {\n",
    "                   \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                   \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                   \"segmentation\": [poly],\n",
    "                   \"category_id\": 0,\n",
    "                   \"iscrowd\": 0\n",
    "                   }\n",
    "            objs.append(obj)\n",
    "            # print(\"#### HERE IS OBJS #####\", objs)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "for d in [\"train\", \"test\"]:\n",
    "    DatasetCatalog.register(\"trees_\" + d, lambda d=d: get_tree_dicts('/home/jovyan/lustre_scratch/paracou_data/high_integrity_data/' + d))\n",
    "    MetadataCatalog.get(\"trees_\" + d).set(thing_classes=['tree'])\n",
    "trees_metadata = MetadataCatalog.get(\"trees_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our training image and annos for our geojson sepilok dataset!!!\n",
    "\n",
    "dataset_dicts = get_tree_dicts(\"/home/jovyan/lustre_scratch/paracou_data/high_integrity_data/train\")\n",
    "for d in random.sample(dataset_dicts, 1):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=trees_metadata, scale=0.4)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    image = cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)\n",
    "    #display(Image.fromarray(img))\n",
    "    display(Image.fromarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup the evaluator\n",
    "\n",
    "from detectron2.evaluation import (\n",
    "    CityscapesInstanceEvaluator,\n",
    "    CityscapesSemSegEvaluator,\n",
    "    COCOEvaluator,\n",
    "    COCOPanopticEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    LVISEvaluator,\n",
    "    PascalVOCDetectionEvaluator,\n",
    "    SemSegEvaluator,\n",
    "    verify_results,\n",
    ")\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c60b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.evaluation import inference_context\n",
    "from detectron2.utils.logger import log_every_n_seconds\n",
    "from detectron2.data import DatasetMapper, build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.utils.comm as comm\n",
    "#import torch\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class LossEvalHook(HookBase):\n",
    "    def __init__(self, eval_period, model, data_loader):\n",
    "        self._model = model\n",
    "        self._period = eval_period\n",
    "        self._data_loader = data_loader\n",
    "    \n",
    "    def _do_loss_eval(self):\n",
    "        # Copying inference_on_dataset from evaluator.py\n",
    "        total = len(self._data_loader)\n",
    "        num_warmup = min(5, total - 1)\n",
    "            \n",
    "        start_time = time.perf_counter()\n",
    "        total_compute_time = 0\n",
    "        losses = []\n",
    "        for idx, inputs in enumerate(self._data_loader):            \n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            start_compute_time = time.perf_counter()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    ),\n",
    "                    n=5,\n",
    "                )\n",
    "            loss_batch = self._get_loss(inputs)\n",
    "            losses.append(loss_batch)\n",
    "        mean_loss = np.mean(losses)\n",
    "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
    "        comm.synchronize()\n",
    "\n",
    "        return losses\n",
    "            \n",
    "    def _get_loss(self, data):\n",
    "        # How loss is calculated on train_loop \n",
    "        metrics_dict = self._model(data)\n",
    "        metrics_dict = {\n",
    "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
    "            for k, v in metrics_dict.items()\n",
    "        }\n",
    "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
    "        return total_losses_reduced\n",
    "        \n",
    "        \n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        is_final = next_iter == self.trainer.max_iter\n",
    "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
    "            self._do_loss_eval()\n",
    "        self.trainer.storage.put_scalars(timetest=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5968cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"trees_train\",)\n",
    "cfg.DATASETS.TEST = (\"trees_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 900\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(\"eval_2\", exist_ok=True)\n",
    "            output_folder = \"eval_2\"\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "                     \n",
    "    def build_hooks(self):\n",
    "        hooks = super().build_hooks()\n",
    "        hooks.insert(-1,LossEvalHook(\n",
    "            cfg.TEST.EVAL_PERIOD,\n",
    "            self.model,\n",
    "            build_detection_test_loader(\n",
    "                self.cfg,\n",
    "                self.cfg.DATASETS.TEST[0],\n",
    "                DatasetMapper(self.cfg,True)\n",
    "            )\n",
    "        ))\n",
    "        return hooks\n",
    "\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=[T.Resize((800, 800)), T.RandomBrightness(0.8, 1.8), \n",
    "        T.RandomContrast(0.6, 1.3), T.RandomSaturation(0.8, 1.4), T.RandomRotation(angle=[90, 90], expand=False), T.RandomLighting(0.7),\n",
    "        T.RandomFlip(prob=0.4, horizontal=False, vertical=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63996150",
   "metadata": {},
   "outputs": [],
   "source": [
    "### see if we can mess with resolution inside augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f9e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to rewrite this to not use DefaultTrainer/DefaultPredictor. This will allow extraction of masks more easily. Pay attention to this. 18/6/21\n",
    "### have now done this. I am sick.\n",
    "# Train! Can change hyperparameters e.g. learning rate\n",
    "# This works excellently, 15/6/21\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"trees_train\",)\n",
    "cfg.DATASETS.TEST = (\"trees_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 900\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "\n",
    "### From here is the important bit that hasn't been repeated further up\n",
    "#cfg.TEST.EVAL_PERIOD = 10\n",
    "\n",
    "# make clear where the output file each time\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = MyTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "#eval_results = inference_on_dataset(trainer.model, val_loader, DatasetEvaluators(evaluator))\n",
    "\n",
    "\n",
    "#trainer.test(cfg, trainer.model, evaluator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bc102",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot training and validation loss on the same plot to check how the training has gone\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment_folder = '/home/jovyan/detectron2_live/train_test/output'\n",
    "\n",
    "def load_json_arr(json_path):\n",
    "    lines = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        for line in f:\n",
    "            lines.append(json.loads(line))\n",
    "    return lines\n",
    "\n",
    "experiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\n",
    "\n",
    "plt.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'validation_loss' in x], \n",
    "    [x['validation_loss'] for x in experiment_metrics if 'validation_loss' in x], label='Total Validation Loss', color='red')\n",
    "plt.plot(\n",
    "    [x['iteration'] for x in experiment_metrics if 'total_loss' in x], \n",
    "    [x['total_loss'] for x in experiment_metrics if 'total_loss' in x], label='Total Training Loss')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Comparison of the training and validation loss of Mask R-CNN')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
