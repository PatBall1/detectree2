{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started: Your First Prediction\n",
    "\n",
    "This notebook provides a concise, end-to-end walkthrough to get you from an orthomosaic to a final crown prediction map using **detectree2**.\n",
    "\n",
    "The key steps are:\n",
    "1. Preparing data (tiling)\n",
    "2. Training a model\n",
    "3. Making landscape-level predictions\n",
    "\n",
    "For the full tutorial, see the [documentation](https://patball1.github.io/detectree2/tutorials/01_getting_started.html).\n",
    "\n",
    "Example data is available on [Zenodo](https://zenodo.org/records/8136161)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "!pip install detectree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Data\n",
    "\n",
    "First, we tile our large orthomosaic and crown data into smaller images suitable for training.\n",
    "\n",
    "You will need:\n",
    "- An orthomosaic (`.tif`)\n",
    "- Corresponding tree crown polygons (`.gpkg` or `.shp`)\n",
    "\n",
    "For best results, manual crowns should be supplied as dense clusters rather than sparsely scattered across the landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectree2.preprocessing.tiling import tile_data, to_traintest_folders\n",
    "import geopandas as gpd\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up input paths\n",
    "site_path = \"./Paracou\"  # Example path\n",
    "img_path = site_path + \"/rgb/Paracou_RGB_2016_10cm.tif\"\n",
    "crown_path = site_path + \"/crowns/UpdatedCrowns8.gpkg\"\n",
    "\n",
    "# Read in crowns and match CRS to the image\n",
    "data = rasterio.open(img_path)\n",
    "crowns = gpd.read_file(crown_path)\n",
    "crowns = crowns.to_crs(data.crs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tiling parameters\n",
    "buffer = 30\n",
    "tile_width = 40\n",
    "tile_height = 40\n",
    "threshold = 0.6\n",
    "out_dir = site_path + \"/tiles/\"\n",
    "\n",
    "# Tile the data for training\n",
    "tile_data(img_path, out_dir, buffer, tile_width, tile_height, crowns, threshold, mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test folders\n",
    "to_traintest_folders(out_dir, out_dir, test_frac=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training a Model\n",
    "\n",
    "Register the training data, configure the model, and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectree2.models.train import register_train_data, MyTrainer, setup_cfg\n",
    "\n",
    "train_location = out_dir + \"/train/\"\n",
    "register_train_data(train_location, 'Paracou', val_fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base (pre-trained) model from the detectron2 model_zoo\n",
    "base_model = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
    "\n",
    "trains = (\"Paracou_train\",)  # Registered train data\n",
    "tests = (\"Paracou_val\",)    # Registered validation data\n",
    "\n",
    "model_output_dir = \"./train_outputs\"\n",
    "\n",
    "cfg = setup_cfg(base_model, trains, tests, workers=4, eval_period=100, max_iter=3000, out_dir=model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MyTrainer(cfg, patience=5)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making Landscape-Level Predictions\n",
    "\n",
    "Tile the full orthomosaic, run predictions, then project back to geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectree2.models.predict import predict_on_data\n",
    "from detectree2.models.outputs import project_to_geojson, stitch_crowns, clean_crowns\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "# Path to the full orthomosaic\n",
    "img_path = site_path + \"/rgb/Paracou_RGB_2016_10cm.tif\"\n",
    "pred_tiles_path = site_path + \"/tiles_pred/\"\n",
    "\n",
    "# Specify tiling parameters (should be similar to training)\n",
    "buffer = 30\n",
    "tile_width = 40\n",
    "tile_height = 40\n",
    "tile_data(img_path, pred_tiles_path, buffer, tile_width, tile_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use your own trained model or download a pre-trained one\n",
    "# !wget https://zenodo.org/records/15863800/files/250312_flexi.pth\n",
    "\n",
    "trained_model = \"./230103_randresize_full.pth\"\n",
    "cfg = setup_cfg(update_model=trained_model)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "predict_on_data(pred_tiles_path, predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project tile predictions to geo-referenced crowns\n",
    "project_to_geojson(pred_tiles_path, pred_tiles_path + \"predictions/\", pred_tiles_path + \"predictions_geo/\")\n",
    "\n",
    "# Stitch and clean crowns\n",
    "crowns = stitch_crowns(pred_tiles_path + \"predictions_geo/\")\n",
    "clean = clean_crowns(crowns, 0.6, confidence=0.5)  # Filter low-confidence and overlapping crowns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Saving and Visualizing\n",
    "\n",
    "Save the cleaned crown map. You can view the output in QGIS or ArcGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify geometries for easier editing in GIS software\n",
    "clean = clean.set_geometry(clean.simplify(0.3))\n",
    "\n",
    "# Save to file\n",
    "clean.to_file(site_path + \"/crowns_out.gpkg\", driver=\"GPKG\")"
   ]
  }
 ]
}
